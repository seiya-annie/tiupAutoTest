import os
import subprocess
import random
import time
import json
import threading
from uuid import uuid4
from flask import Flask, render_template, request, jsonify, session, redirect, url_for
from packaging.version import Version
import mysql.connector
import sys

# --- é…ç½® ---
app = Flask(__name__)
# ç”¨äº session åŠ å¯†ï¼Œè¯·åœ¨ç”Ÿäº§ç¯å¢ƒä¸­æ›¿æ¢ä¸ºæ›´å¤æ‚çš„å¯†é’¥
app.secret_key = 'a_very_secret_key_for_tidb_tester_tiup'

# ç”¨äºå­˜å‚¨åå°ä»»åŠ¡çš„çŠ¶æ€å’Œç»“æœ
# tasks å­—å…¸ç°åœ¨ä¹Ÿå­˜å‚¨ Popen è¿›ç¨‹å¯¹è±¡ï¼Œä»¥ä¾¿åç»­æ¸…ç†
tasks = {}
# TiDB ç¼–è¯‘åçš„äºŒè¿›åˆ¶æ–‡ä»¶ç›¸å¯¹è·¯å¾„
TIDB_BINARY_PATH = "bin/tidb-server"
# ç¼–è¯‘å‘½ä»¤
COMPILE_COMMAND = "make"
TIDB_REPO_PATH = '/Users/lt/git/tidb'

# --- commit äºŒåˆ†æŸ¥æ‰¾å‡½æ•° --
def run_command(command, work_dir=".", shell=False, check=True):
    """ä¸€ä¸ªé€šç”¨çš„å‘½ä»¤æ‰§è¡Œå‡½æ•°ï¼Œå®æ—¶æ‰“å°è¾“å‡º"""
    print(f"ğŸš€ åœ¨ '{work_dir}' ä¸­æ‰§è¡Œ: {' '.join(command) if isinstance(command, list) else command}")
    try:
        process = subprocess.Popen(
            command,
            cwd=work_dir,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            text=True,
            shell=shell
        )

        output_lines = []
        for line in iter(process.stdout.readline, ''):
            sys.stdout.write(line)
            output_lines.append(line)

        process.wait()

        if check and process.returncode != 0:
            raise subprocess.CalledProcessError(process.returncode, command)

        return "".join(output_lines)
    except FileNotFoundError:
        print(f"âŒ å‘½ä»¤æœªæ‰¾åˆ°: {command[0]}. è¯·ç¡®ä¿å®ƒå·²å®‰è£…å¹¶åœ¨æ‚¨çš„ PATH ä¸­ã€‚")
        sys.exit(1)

def get_commit_list(start_tag, end_tag,task_id):
    """è·å–ä¸¤ä¸ª tag ä¹‹é—´çš„ commit SHA åˆ—è¡¨ï¼ŒæŒ‰æ—¶é—´æ­£åºæ’åˆ—"""
    tasks[task_id]['log'].append(f"\nâ„¹ï¸ å‡†å¤‡åˆ‡æ¢åˆ°ä¸ tag '{end_tag}' ç›¸å…³çš„ release åˆ†æ”¯...")
    try:
        # ä» 'v8.5.0' -> '8.5.0' -> ['8', '5', '0'] -> '8.5'
        version_parts = end_tag.lstrip('v').split('.')
        branch_version = f"{version_parts[0]}.{version_parts[1]}"
        branch_name = f"release-{branch_version}"

        # ä½¿ç”¨ -f å¼ºåˆ¶åˆ‡æ¢ï¼Œå¿½ç•¥æœ¬åœ°æœªæäº¤çš„ä¿®æ”¹
        run_command(["git", "checkout", "-f", branch_name], work_dir=TIDB_REPO_PATH)
        tasks[task_id]['log'].append(f"âœ… æˆåŠŸåˆ‡æ¢åˆ°åˆ†æ”¯: {branch_name}")

    except IndexError:
        tasks[task_id]['log'].append(f"âš ï¸ è­¦å‘Š: æ— æ³•ä» tag '{end_tag}' æ¨æ–­å‡ºæ ‡å‡†çš„ release åˆ†æ”¯åã€‚è·³è¿‡ checkoutã€‚")
    except subprocess.CalledProcessError:
        tasks[task_id]['log'].append(f"âš ï¸ è­¦å‘Š: åˆ‡æ¢åˆ°åˆ†æ”¯ '{branch_name}' å¤±è´¥ã€‚è¯¥åˆ†æ”¯å¯èƒ½åœ¨æœ¬åœ°ä¸å­˜åœ¨ã€‚")
        tasks[task_id]['log'].append("ç»§ç»­å°è¯•ç›´æ¥ä½¿ç”¨ tag è¿›è¡Œ commit æŸ¥æ‰¾...")

    command = ["git", "rev-list", "--reverse", f"{start_tag}...{end_tag}"]
    output = run_command(command, TIDB_REPO_PATH)
    tasks[task_id]['log'].append(f"\nğŸ” è·å– {start_tag}..{end_tag} ä¹‹é—´çš„ commit åˆ—è¡¨...")
    # --reverse å‚æ•°è®© commit ä»æ—§åˆ°æ–°æ’åˆ—ï¼Œç¬¦åˆäºŒåˆ†æŸ¥æ‰¾çš„é€»è¾‘é¡ºåº
    command = ["git", "rev-list", "--reverse", f"{start_tag}...{end_tag}"]
    output = run_command(command, TIDB_REPO_PATH)
    commits = output.strip().split('\n')
    tasks[task_id]['log'].append(f"âœ… æ‰¾åˆ° {len(commits)} ä¸ª commitsã€‚")
    return [c for c in commits if c] # è¿‡æ»¤ç©ºè¡Œ


def compile_at_commit(commit_sha,task_id):
    """Checkout åˆ°æŒ‡å®š commit å¹¶è¿›è¡Œç¼–è¯‘"""
    tasks[task_id]['log'].append(f"\nğŸ”§ åˆ‡æ¢åˆ° commit: {commit_sha[:8]} å¹¶å¼€å§‹ç¼–è¯‘...")
    try:
        run_command(["git", "checkout", commit_sha], work_dir=TIDB_REPO_PATH)
        # ç¼–è¯‘ TiDB server
        run_command(COMPILE_COMMAND.split(), work_dir=TIDB_REPO_PATH)

        binary_full_path = os.path.join(TIDB_REPO_PATH, TIDB_BINARY_PATH)
        if not os.path.exists(binary_full_path):
            raise FileNotFoundError(f"ç¼–è¯‘äº§ç‰© {binary_full_path} æœªæ‰¾åˆ°ï¼")

        tasks[task_id]['log'].append(f"âœ… ç¼–è¯‘æˆåŠŸ: {binary_full_path}")
        return binary_full_path
    except subprocess.CalledProcessError as e:
        tasks[task_id]['log'].append(f"âŒ åœ¨ commit {commit_sha[:8]} ç¼–è¯‘å¤±è´¥ï¼")
        # åœ¨äºŒåˆ†æŸ¥æ‰¾ä¸­ï¼Œç¼–è¯‘å¤±è´¥é€šå¸¸è¢«è§†ä¸º "bad" commit
        return None

# --- è¾…åŠ©å‡½æ•° ---

def get_tidb_versions():
    """é€šè¿‡ tiup list tidb è·å–å¯ç”¨çš„ TiDB ç‰ˆæœ¬åˆ—è¡¨"""
    try:
        subprocess.run(["tiup", "update", "--self"], check=True, capture_output=True, text=True, timeout=120)
        result = subprocess.run(
            ["tiup", "list", "tidb"],
            check=True,
            capture_output=True,
            text=True,
            timeout=60
        )
        versions = []
        for line in result.stdout.splitlines():
            if line.strip().startswith('v') and 'Available versions' not in line and '---' not in line:
                version = line.split()[0]
                if all(c in 'v0123456789.' for c in version):
                    versions.append(version)
        versions.sort(key=Version, reverse=True)
        # versions.insert(0, "nightly")
        return versions

    except Exception as e:
        print(f"è·å– TiDB ç‰ˆæœ¬å¤±è´¥: {e}")
        return ["v8.1.0", "v8.0.0", "v7.5.1", "v7.1.3", "v6.5.9", "v6.1.7", "v5.4.3", "v4.0.16"]


def run_sql_on_tidb(sql, port):
    """åœ¨æŒ‡å®šçš„ TiDB å®ä¾‹ä¸Šæ‰§è¡Œ SQL"""
    result_str = ""
    try:
        conn = mysql.connector.connect(
            host='127.0.0.1',
            port=port,
            user='root',
            password='',
            database='test',
            connection_timeout=20
        )
        cursor = conn.cursor()
        for stmt in sql.split(';'):
            if stmt.strip():
                cursor.execute(stmt)
                if cursor.with_rows:
                    rows = cursor.fetchall()
                    result_str += str(rows) + "\n"
        conn.commit()
        cursor.close()
        conn.close()
        return result_str.strip(), True
    except mysql.connector.Error as err:
        print(f"SQL æ‰§è¡Œå¤±è´¥")
        return str(err), False


def test_single_version(version, sql, expected_result, task_id, index, cleanup_after=False, commit=''):
    """ä½¿ç”¨ tiup playground å¯åŠ¨ä¸€ä¸ª TiDB é›†ç¾¤å¹¶æ‰§è¡Œæµ‹è¯•"""
    port_offset = random.randint(10000, 30000)
    sql_port = 4000 + port_offset
    dashboard_port = 2379 + port_offset

    log_dir = "logs"
    os.makedirs(log_dir, exist_ok=True)
    log_filename = f"{log_dir}/task_{task_id[:8]}_{version}.log"

    if commit != '':
        log_message = f"commit {commit}: å‡†å¤‡å¯åŠ¨é›†ç¾¤ (ç«¯å£åç§»: {port_offset}, SQL Port: {sql_port})..."
    else:
        log_message = f"ç‰ˆæœ¬ {version}: å‡†å¤‡å¯åŠ¨é›†ç¾¤ (ç«¯å£åç§»: {port_offset}, SQL Port: {sql_port})..."

    tasks[task_id]['log'].append(log_message)

    process = None
    log_file = None
    try:
        log_file = open(log_filename, 'w', encoding='utf-8')
        if commit != '':
            binary_full_path = os.path.join(TIDB_REPO_PATH, TIDB_BINARY_PATH)
            cmd = ['tiup', 'playground', f'--db.binpath={binary_full_path}', version, f'--port-offset={port_offset}', '--without-monitor',"--kv", "3", "--tiflash", "1"]
            print("install use a binary")
        else:
            cmd = ['tiup', 'playground', version, f'--port-offset={port_offset}', '--without-monitor', "--kv", "3",
                   "--tiflash", "1"]
            # print("install use a version")

        # ä½¿ç”¨ Popen å¯åŠ¨éé˜»å¡çš„å­è¿›ç¨‹
        process = subprocess.Popen(cmd, stdout=log_file, stderr=log_file, text=True, encoding='utf-8')

        # å°†è¿›ç¨‹å¯¹è±¡å’Œç‰ˆæœ¬ä¿¡æ¯å­˜å…¥ taskï¼Œä»¥ä¾¿åç»­æ¸…ç†
        tasks[task_id]['processes'].append({'version': version, 'process': process, 'offset': port_offset,'log_file': log_filename})

        if commit != '':
            log_message = f"commit {commit}: é›†ç¾¤è¿›ç¨‹å·²å¯åŠ¨ (PID: {process.pid})ï¼Œç­‰å¾… TiDB æœåŠ¡å°±ç»ª..."
        else:
            log_message = f"ç‰ˆæœ¬ {version}: é›†ç¾¤è¿›ç¨‹å·²å¯åŠ¨ (PID: {process.pid})ï¼Œç­‰å¾… TiDB æœåŠ¡å°±ç»ª..."
        tasks[task_id]['log'].append(log_message)

        ready = False
        # ç­‰å¾… TiDB å‡†å¤‡å°±ç»ªï¼Œæœ€å¤šç­‰å¾… 180 ç§’
        for _ in range(36):
            time.sleep(5)
            try:
                conn = mysql.connector.connect(host='127.0.0.1', port=sql_port, user='root', password='',
                                               connection_timeout=5)
                conn.close()
                ready = True
                if commit != '':
                    log_message = f"commit {commit}: TiDB æœåŠ¡åœ¨ç«¯å£ {sql_port} ä¸Šå·²å°±ç»ªã€‚"
                else:
                    log_message = f"ç‰ˆæœ¬ {version}: TiDB æœåŠ¡åœ¨ç«¯å£ {sql_port} ä¸Šå·²å°±ç»ªã€‚"
                tasks[task_id]['log'].append(log_message)
                break
            except mysql.connector.Error:
                # æ£€æŸ¥è¿›ç¨‹æ˜¯å¦æ„å¤–é€€å‡º
                if process.poll() is not None:
                    raise Exception(f"TiUP è¿›ç¨‹æ„å¤–é€€å‡ºã€‚Stderr: {process.stderr.read()}")
                continue

        if not ready:
            raise Exception("TiDB æœåŠ¡å¯åŠ¨è¶…æ—¶")

        # å¦‚æœä¸Šcommit å®šä½è¿‡ç¨‹ï¼Œéœ€è¦åœ¨æµ‹è¯•å‰ç¡®è®¤ä¸€ä¸‹commitæ˜¯å¦ä¸€è‡´ã€‚
        if commit != '':
            sql_check = 'select tidb_version();'
            v_result, success = run_sql_on_tidb(sql_check, sql_port)
            if commit not in ''.join(v_result.split()):
                tasks[task_id]['log'].append("tidb binary is not correct")
                raise Exception(f"TiUP è¿›ç¨‹æ„å¤–é€€å‡ºã€‚Stderr: {process.stderr.read()}")
            tasks[task_id]['log'].append("check tidb binary version pass.")

        actual_result, success = run_sql_on_tidb(sql, sql_port)

        if ''.join(expected_result.split()) in ''.join(actual_result.split()):
            status = "æˆåŠŸ"
        else:
            status = "å¤±è´¥"
        if commit != '':
            version_commit = f"{version}-{commit}"
            result_data = {
                'version': version_commit, 'status': status, 'sql_port': sql_port,
                'dashboard_port': dashboard_port, 'expected': expected_result, 'actual': actual_result
            }
        else:
            result_data = {
                'version': version, 'status': status, 'sql_port': sql_port,
                'dashboard_port': dashboard_port, 'expected': expected_result, 'actual': actual_result
            }

    except Exception as e:
        error_msg = f"æµ‹è¯•ç‰ˆæœ¬ {version} æ—¶å‘ç”Ÿé”™è¯¯: {e}"
        tasks[task_id]['log'].append(error_msg)
        result_data = {'version': version, 'status': 'å¤±è´¥', 'error': str(e)}
    finally:
        # åœ¨äºŒåˆ†æŸ¥æ‰¾æ¨¡å¼ä¸‹ï¼Œæµ‹è¯•å®Œä¸€ä¸ªç‰ˆæœ¬å°±ç«‹å³æ¸…ç†
        if log_file:
            log_file.close() # å…³é—­æ—¥å¿—æ–‡ä»¶å¥æŸ„
        if cleanup_after and process:
            if commit != '':
                tasks[task_id]['log'].append(f"commit {commit}: æµ‹è¯•å®Œæˆï¼Œæ¸…ç†é›†ç¾¤ (PID: {process.pid})...")
            else:
                tasks[task_id]['log'].append(f"ç‰ˆæœ¬ {commit}: æµ‹è¯•å®Œæˆï¼Œæ¸…ç†é›†ç¾¤ (PID: {process.pid})...")
            process.terminate()
            process.wait()

    tasks[task_id]['results'][index] = result_data


# --- è·¯ç”± ---

@app.route('/')
def index():
    versions = get_tidb_versions()
    return render_template('index.html', versions=versions)


@app.route('/locate')
def locate():
    return render_template('locate.html')


@app.route('/start_test', methods=['POST'])
def start_test():
    data = request.json
    selected_versions = data.get('versions', [])
    sql = data.get('sql')
    expected_result = data.get('expected')

    task_id = str(uuid4())
    tasks[task_id] = {
        'status': 'running', 'log': [],
        'results': [{} for _ in selected_versions],  # å ä½
        'processes': [], 'type': 'test'
    }
    session.setdefault('task_ids', []).append(task_id)
    session.modified = True

    threads = []
    for i, version in enumerate(selected_versions):
        thread = threading.Thread(target=test_single_version, args=(version, sql, expected_result, task_id, i, False))
        threads.append(thread)
        thread.start()

    def wait_for_completion():
        for t in threads:
            t.join()
        tasks[task_id]['status'] = 'complete'

    threading.Thread(target=wait_for_completion).start()

    return jsonify({'task_id': task_id})


def run_binary_search(start_v_str, end_v_str, sql, expected, task_id):
    """äºŒåˆ†æŸ¥æ‰¾é€»è¾‘"""
    all_versions = get_tidb_versions()

    def commit_binary_search_logic(start_version, end_version):
        commits = get_commit_list(start_version, end_version, task_id)
        if not commits:
            print("åœ¨æŒ‡å®šçš„ tag èŒƒå›´å†…æœªæ‰¾åˆ°ä»»ä½• commitã€‚")
            return

        tasks[task_id]['log'].append(f"å¼€å§‹åœ¨ {commits[0]} åˆ° {commits[-1]} ä¹‹é—´è¿›è¡ŒäºŒåˆ†æŸ¥æ‰¾...")

        low, high = 0, len(commits) - 1
        first_bad_commit = None

        while low <= high:
            mid = (low + high) // 2
            commit_sha = commits[mid]

            tasks[task_id]['log'].append(f"\n--- æ­£åœ¨æµ‹è¯•ç¬¬ {mid + 1}/{len(commits)} ä¸ª commit: {commit_sha[:12]} ---")
            binary_path = compile_at_commit(commit_sha, task_id)
            if binary_path is None:
                print(f"ğŸ‘ [BAD] Commit {commit_sha[:12]} ç¼–è¯‘å¤±è´¥ã€‚")
                first_bad_commit = commit_sha
                high = mid - 1
                continue
            result_index = len(tasks[task_id]['results'])
            tasks[task_id]['results'].append({})  # å ä½
            # cleanup_after=True è¡¨ç¤ºæµ‹è¯•å®Œå°±æ¸…ç†
            test_single_version(end_version, sql, expected, task_id, result_index, cleanup_after=True,
                                commit=commit_sha)

            result_data = tasks[task_id]['results'][result_index]

            if result_data.get('status') == 'å¤±è´¥':
                first_bad_commit = commit_sha
                high = mid - 1
            elif result_data.get('status') == 'æˆåŠŸ':
                low = mid + 1
            else:
                tasks[task_id]['log'].append(f"ç‰ˆæœ¬ {commit_sha} æµ‹è¯•æ—¶å‘ç”Ÿç¯å¢ƒé”™è¯¯ï¼Œå®šä½ä¸­æ­¢ã€‚")
                tasks[task_id]['status'] = 'error'
                return None

        return first_bad_commit

    def binary_search_logic(start_version, end_version):
        search_space = [
            v for v in all_versions
            if Version(v) >= Version(start_version) and Version(v) <= Version(end_version)
        ]
        search_space.sort(key=Version)

        tasks[task_id]['log'].append(f"å¼€å§‹åœ¨ {start_version} åˆ° {end_version} ä¹‹é—´è¿›è¡ŒäºŒåˆ†æŸ¥æ‰¾...")
        tasks[task_id]['log'].append(f"å¾…æŸ¥æ‰¾çš„ç‰ˆæœ¬åˆ—è¡¨: {search_space}")

        low, high = 0, len(search_space) - 1
        first_bad_version = None

        while low <= high:
            mid_idx = (low + high) // 2
            version_to_test = search_space[mid_idx]

            result_index = len(tasks[task_id]['results'])
            tasks[task_id]['results'].append({})  # å ä½
            # cleanup_after=True è¡¨ç¤ºæµ‹è¯•å®Œå°±æ¸…ç†
            test_single_version(version_to_test, sql, expected, task_id, result_index, cleanup_after=True)

            result_data = tasks[task_id]['results'][result_index]

            if result_data.get('status') == 'å¤±è´¥':
                first_bad_version = version_to_test
                high = mid_idx - 1
            elif result_data.get('status') == 'æˆåŠŸ':
                low = mid_idx + 1
            else:
                tasks[task_id]['log'].append(f"ç‰ˆæœ¬ {version_to_test} æµ‹è¯•æ—¶å‘ç”Ÿç¯å¢ƒé”™è¯¯ï¼Œå®šä½ä¸­æ­¢ã€‚")
                tasks[task_id]['status'] = 'error'
                return None

        return first_bad_version

    # åŸºçº¿ç‰ˆæœ¬æµ‹è¯•
    if start_v_str == "v5.4.0":
        tasks[task_id]['log'].append("æ£€æŸ¥åŸºçº¿ç‰ˆæœ¬ v5.4.0...")
        # ã€ä¿®å¤ã€‘ä¸º v5.4.0 æµ‹è¯•æ·»åŠ å ä½ç¬¦
        tasks[task_id]['results'].append({})
        test_single_version("v5.4.0", sql, expected, task_id, 0)
        # ç¡®ä¿æµ‹è¯•çº¿ç¨‹æœ‰æ—¶é—´å†™å…¥ç»“æœ
        time.sleep(0.1)
        v540_result = tasks[task_id]['results'][0]

        if v540_result.get('status') == 'å¤±è´¥' and 'error' not in v540_result:
            tasks[task_id]['log'].append("v5.4.0 ä¸Šçš„ç»“æœå·²ä¸ç¬¦åˆé¢„æœŸï¼Œå°†åœ¨ v3.0.0 å’Œ v5.3.0 ä¹‹é—´æŸ¥æ‰¾ã€‚")
            start_v_str = "v3.0.0"
            end_v_str = "v5.3.0"
        elif v540_result.get('status') == 'æˆåŠŸ':
            start_v_str = "v5.4.1"

    found_version = binary_search_logic(start_v_str, end_v_str)
    tasks[task_id][
        'final_result'] = f"å®šä½åˆ°ç¬¬ä¸€ä¸ªå‡ºé”™çš„ç‰ˆæœ¬æ˜¯: {found_version}" if found_version else f"åœ¨ {start_v_str}-{end_v_str} èŒƒå›´å†…æœªæ‰¾åˆ°ä¸ç¬¦åˆé¢„æœŸçš„ç‰ˆæœ¬ã€‚"

    if found_version:
        tidb_versions = get_tidb_versions()
        start_version_index = tidb_versions.index(found_version) + 1
        found_commit = commit_binary_search_logic(tidb_versions[start_version_index], found_version)
        tasks[task_id][
            'final_result'] = f"å®šä½åˆ°ç¬¬ä¸€ä¸ªå‡ºé”™çš„commitæ˜¯: {found_version}-{found_commit}, " if found_commit else f"åœ¨ {start_v_str} èŒƒå›´å†…æœªæ‰¾åˆ°ä¸ç¬¦åˆé¢„æœŸçš„commitã€‚"

    tasks[task_id]['status'] = 'complete'


@app.route('/start_locate', methods=['POST'])
def start_locate():
    data = request.json
    bug_version = data.get('bug_version')
    start_version_str = data.get('start_version') or "v5.4.0"
    sql = data.get('sql')
    expected_result = data.get('expected')

    if not bug_version:
        return jsonify({'error': 'â€œbug ä¸ŠæŠ¥ç‰ˆæœ¬â€ä¸èƒ½ä¸ºç©º'}), 400
    try:
        if Version(start_version_str) >= Version(bug_version):
            return jsonify({'error': 'â€œèµ·å§‹ç‰ˆæœ¬â€ä¸èƒ½ç­‰äºæˆ–è€…æ™šäºâ€œbug ä¸ŠæŠ¥ç‰ˆæœ¬â€'}), 400
    except Exception:
        return jsonify({'error': 'ç‰ˆæœ¬å·æ ¼å¼æ— æ•ˆ'}), 400

    task_id = str(uuid4())
    tasks[task_id] = {
        'status': 'running', 'log': [], 'results': [],
        'processes': [], 'type': 'locate'
    }
    session.setdefault('task_ids', []).append(task_id)
    session.modified = True

    thread = threading.Thread(target=run_binary_search,
                              args=(start_version_str, bug_version, sql, expected_result, task_id))
    thread.start()

    return jsonify({'task_id': task_id})


@app.route('/status/<task_id>')
@app.route('/status/<task_id>')
def task_status(task_id):
    """è·å–ä»»åŠ¡çŠ¶æ€ (ä¿®æ­£ç‰ˆ)"""
    task = tasks.get(task_id)
    if not task:
        return jsonify({'status': 'not_found'}), 404

    # åˆ›å»ºä¸€ä¸ªå¯åºåˆ—åŒ–ï¼ˆå¯è½¬æ¢ä¸º JSONï¼‰çš„ä»»åŠ¡å‰¯æœ¬
    # ä¸è¦ç›´æ¥ä¿®æ”¹åŸå§‹çš„ task å­—å…¸ï¼Œå› ä¸ºæˆ‘ä»¬è¿˜éœ€è¦é‡Œé¢çš„ Popen å¯¹è±¡æ¥æ¸…ç†è¿›ç¨‹
    serializable_task = {
        'status': task.get('status'),
        'log': task.get('log', []),
        'results': task.get('results', []),
        'type': task.get('type'),
        'final_result': task.get('final_result'),
        'processes_info': [] # åˆ›å»ºä¸€ä¸ªæ–°çš„åˆ—è¡¨æ¥å­˜æ”¾è¿›ç¨‹ä¿¡æ¯
    }

    # éå†åŸå§‹ä»»åŠ¡ä¸­çš„è¿›ç¨‹åˆ—è¡¨
    if 'processes' in task:
        for proc_info in task['processes']:
            process = proc_info.get('process')
            # å°† Popen å¯¹è±¡æ›¿æ¢ä¸ºå®ƒçš„ PID (ä¸€ä¸ªç®€å•çš„æ•´æ•°)
            serializable_task['processes_info'].append({
                'version': proc_info.get('version'),
                'pid': process.pid if process else None,
                'offset': proc_info.get('offset'),
                # æ£€æŸ¥è¿›ç¨‹æ˜¯å¦è¿˜åœ¨è¿è¡Œ
                'is_running': process.poll() is None if process else False
            })

    # è¿”å›è¿™ä¸ªæ¸…ç†è¿‡åçš„ã€å®‰å…¨çš„å­—å…¸
    return jsonify(serializable_task)


@app.route('/clean', methods=['POST'])
def clean_env():
    """æ¸…ç†å½“å‰ session åˆ›å»ºçš„æ‰€æœ‰ tiup playground è¿›ç¨‹å’Œæ—¥å¿—æ–‡ä»¶ (æ›´æ–°ç‰ˆ)"""
    # This line is at the first level of indentation
    task_ids_to_clean = session.get('task_ids', [])
    cleaned_pids = []
    deleted_logs = []
    errors = []

    # The 'for' loop is at the first level
    for task_id in task_ids_to_clean:
        # This block is at the second level of indentation
        task = tasks.get(task_id)
        if not task or not task.get('processes'):
            continue
        
        # This 'for' loop is at the second level
        for proc_info in task['processes']:
            # This block is at the third level of indentation
            # 1. ç»ˆæ­¢è¿›ç¨‹
            process = proc_info.get('process')
            if process and process.poll() is None:
                # This block is at the fourth level
                try:
                    pid = process.pid
                    process.terminate()
                    process.wait(timeout=10)
                    cleaned_pids.append(pid)
                except Exception as e:
                    errors.append(f"æ¸…ç†è¿›ç¨‹ PID {pid} å¤±è´¥: {e}")
            
            # 2. åˆ é™¤æ—¥å¿—æ–‡ä»¶ (This block is at the third level)
            log_file = proc_info.get('log_file')
            if log_file and os.path.exists(log_file): # <-- This is the corrected line
                # This block is at the fourth level
                try:
                    os.remove(log_file)
                    deleted_logs.append(log_file)
                except OSError as e:
                    errors.append(f"åˆ é™¤æ—¥å¿—æ–‡ä»¶ {log_file} å¤±è´¥: {e}")

    # This block is back at the first level
    session['task_ids'] = []
    session.modified = True
    
    return jsonify({
        'cleaned_pids': cleaned_pids,
        'deleted_logs': deleted_logs,
        'errors': errors
    })

if __name__ == '__main__':
    app.run(debug=True, host='0.0.0.0', port=5001)
