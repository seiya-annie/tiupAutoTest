import os
import subprocess
import random
import time
import threading
from uuid import uuid4
from flask import Flask, render_template, request, jsonify, session, send_from_directory
from packaging.version import Version
import mysql.connector
import sys
import stat
import ast
import shutil
from functools import wraps


def retry(max_retries=3, delay=5):
    """
    ä¸€ä¸ªè£…é¥°å™¨ï¼Œç”¨äºåœ¨å‡½æ•°å¤±è´¥æ—¶è‡ªåŠ¨é‡è¯•ã€‚
    å¤±è´¥çš„æ¡ä»¶æ˜¯ï¼šå‡½æ•°æŠ›å‡ºä»»ä½•å¼‚å¸¸ï¼Œæˆ–è€…å‡½æ•°è¿”å› Noneã€‚
    """

    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            # å°è¯•ä»å‚æ•°ä¸­æ™ºèƒ½åœ°è·å– task_id ç”¨äºæ—¥å¿—è®°å½•
            task_id = kwargs.get('task_id')
            if not task_id:
                for arg in args:
                    if isinstance(arg, str) and len(arg) > 30:  # æ ¹æ® uuid çš„ç‰¹å¾çŒœæµ‹ task_id
                        task_id = arg
                        break

            last_exception = None
            for attempt in range(1, max_retries + 1):
                try:
                    result = func(*args, **kwargs)
                    # å¦‚æœå‡½æ•°é€šè¿‡è¿”å› None æ¥è¡¨ç¤ºå¤±è´¥ï¼Œæˆ‘ä»¬ä¹Ÿå°†å…¶è§†ä¸ºéœ€è¦é‡è¯•çš„å¤±è´¥
                    if result is not None:
                        return result

                    log_msg = f"âš ï¸ å‡½æ•° {func.__name__} ç¬¬ {attempt}/{max_retries} æ¬¡å°è¯•å¤±è´¥ï¼Œç»“æœä¸º Noneã€‚"
                    if attempt == max_retries:  # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥
                        last_exception = Exception("å‡½æ•°è¿”å› None")

                except Exception as e:
                    last_exception = e
                    log_msg = f"âŒ å‡½æ•° {func.__name__} ç¬¬ {attempt}/{max_retries} æ¬¡å°è¯•å¤±è´¥ï¼Œå‘ç”Ÿå¼‚å¸¸: {e}"

                # è®°å½•æ—¥å¿—
                print(log_msg)
                if task_id and task_id in tasks:
                    tasks[task_id]['log'].append(log_msg)

                if attempt < max_retries:
                    time.sleep(delay)

            # æ‰€æœ‰é‡è¯•å‡å‘Šå¤±è´¥
            final_log_msg = f"âŒ å‡½æ•° {func.__name__} åœ¨ {max_retries} æ¬¡å°è¯•åå½»åº•å¤±è´¥ã€‚æœ€åä¸€æ¬¡é”™è¯¯: {last_exception}"
            print(final_log_msg)
            if task_id and task_id in tasks:
                tasks[task_id]['log'].append(final_log_msg)

            return None  # è¿”å› None è¡¨ç¤ºæœ€ç»ˆå¤±è´¥

        return wrapper

    return decorator


TIDB_GO_VERSION_MAP = {
    "4.0": "1.13.15",
    "5.0": "1.13.15",
    "5.1": "1.16.15",
    "5.2": "1.16.15",
    "5.3": "1.16.15",
    "5.4": "1.16.15",
    "6.0": "1.18.10",
    "6.1": "1.18.10",
    "6.2": "1.18.10",
    "6.3": "1.19.13",
    "6.4": "1.19.13",
    "6.5": "1.19.13",
    "6.6": "1.19.13",
    "7.0": "1.20.14",
    "7.1": "1.20.14",
    "7.2": "1.20.14",
    "7.3": "1.20.14",
    "7.4": "1.21.13",
    "7.5": "1.21.13",
    "7.6": "1.21.13",
    "8.0": "1.21.13",
    "8.1": "1.21.13",
    "8.2": "1.21.13",
    "8.3": "1.21.13",
    "8.4": "1.23.6",
    "8.5": "1.25.1",
}
DEFAULT_GO_VERSION = "1.25.1"

COMPONENT_COUNTS = {
    'tidb': 1,
    'tikv': 1,
    'pd': 1,
    'tiflash': 0
}

# --- é…ç½® ---
app = Flask(__name__)
app.secret_key = 'a_very_secret_key_for_tidb_tester_tiup'

tasks = {}
TIDB_BINARY_PATH = "bin/tidb-server"  # TiDB ç¼–è¯‘åçš„äºŒè¿›åˆ¶æ–‡ä»¶ç›¸å¯¹è·¯å¾„
COMPILE_COMMAND = "make"  # ç¼–è¯‘å‘½ä»¤
# æ ¸å¿ƒä»£ç ä»“åº“è·¯å¾„ï¼ˆä½œä¸º worktree çš„æºï¼‰
TIDB_REPO_PATH = '/root/git/tidb'
# ä¸ºå¹¶å‘ä»»åŠ¡åˆ›å»ºéš”ç¦»å·¥ä½œåŒºçš„åŸºå‡†ç›®å½•
# **é‡è¦**: ç¡®ä¿æ­¤ç›®å½•å­˜åœ¨ä¸” Flask åº”ç”¨æœ‰æƒè¯»å†™
TIDB_WORKTREE_BASE = '/tmp/tidb_worktrees'


# --- commit äºŒåˆ†æŸ¥æ‰¾å‡½æ•° --
def run_command(command, work_dir=".", shell=False, check=True, print_output=False, go_version=None):
    """
    ä¸€ä¸ªé€šç”¨çš„å‘½ä»¤æ‰§è¡Œå‡½æ•°ï¼Œå®æ—¶æ‰“å°è¾“å‡ºã€‚
    æ–°å¢ go_version å‚æ•°ä»¥æ”¯æŒæ— çŠ¶æ€çš„ç‰ˆæœ¬åˆ‡æ¢ã€‚
    """
    print(f"ğŸš€ åœ¨ '{work_dir}' ä¸­æ‰§è¡Œ: {' '.join(command) if isinstance(command, list) else command}")

    custom_env = os.environ.copy()
    asdf_script_path = os.path.expanduser("~/.asdf/asdf.sh")

    if not os.path.exists(asdf_script_path):
        print(f"âŒ é”™è¯¯: asdf ç¯å¢ƒè„šæœ¬æœªåœ¨ '{asdf_script_path}' æ‰¾åˆ°ã€‚")
        sys.exit(1)

    command_list = command if isinstance(command, list) else command.split()

    if go_version:
        print(f"ğŸ”§ æ­£åœ¨ä¸ºå‘½ä»¤æ‰‹åŠ¨è®¾ç½® Go {go_version} ç¯å¢ƒ...")
        try:
            # 1. ä½¿ç”¨ asdf where è·å– GOROOT è·¯å¾„
            asdf_where_cmd = f". {asdf_script_path} && asdf where go {go_version}"
            go_root_path = subprocess.check_output(
                ["/bin/bash", "-li", "-c", asdf_where_cmd],
                text=True
            ).strip()

            if not go_root_path or not os.path.exists(go_root_path):
                raise FileNotFoundError(f"asdf æœªèƒ½æ‰¾åˆ° Go {go_version} çš„å®‰è£…è·¯å¾„ã€‚")

            # 2. æ„å»º bin ç›®å½•è·¯å¾„
            go_bin_path = os.path.join(go_root_path, "go/bin")

            # 3. è®¾ç½® GOROOT å’Œ PATH ç¯å¢ƒå˜é‡
            custom_env['GOROOT'] = os.path.join(go_root_path, "go")
            new_path = f"{go_bin_path}:{custom_env.get('PATH', '')}"
            asdf_shims_path = os.path.expanduser("~/.asdf/shims")
            path_parts = new_path.split(':')
            path_parts = [p for p in path_parts if p != asdf_shims_path]
            custom_env['PATH'] = ':'.join(path_parts)
            print(f"âœ… ç¯å¢ƒå·²è®¾ç½®: GOROOT={go_root_path}, PATH å·²æ›´æ–°å¹¶ç§»é™¤äº† asdf shimsã€‚")

            if command_list[0] == 'go':
                go_executable = os.path.join(go_bin_path, 'go')
                if not os.path.exists(go_executable):
                    raise FileNotFoundError(f"Go å¯æ‰§è¡Œæ–‡ä»¶æœªåœ¨é¢„æœŸè·¯å¾„æ‰¾åˆ°: {go_executable}")

                print(f"ğŸ”© å°†å‘½ä»¤ 'go' æ›¿æ¢ä¸ºç»å¯¹è·¯å¾„: {go_executable}")
                command_list[0] = go_executable

        except (subprocess.CalledProcessError, FileNotFoundError) as e:
            print(f"âŒ æ— æ³•ä¸º Go {go_version} è®¾ç½®ç¯å¢ƒ: {e}")
            # æŠ›å‡ºå¼‚å¸¸ä»¥ä¾¿ retry è£…é¥°å™¨å¯ä»¥æ•è·å®ƒ
            raise RuntimeError(f"ä¸º Go {go_version} è®¾ç½®ç¯å¢ƒå¤±è´¥") from e

    use_shell = isinstance(command, str) and shell
    try:
        process = subprocess.Popen(
            command if use_shell else command_list,
            cwd=work_dir,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            text=True,
            shell=use_shell,
            env=custom_env,  # ä½¿ç”¨æˆ‘ä»¬æ‰‹åŠ¨åˆ›å»ºçš„ç¯å¢ƒ
            preexec_fn=os.setsid if sys.platform != "win32" else None
        )

        output_lines, full_output = [], ""
        if print_output:
            for line in iter(process.stdout.readline, ''):
                sys.stdout.write(line)
                output_lines.append(line)
            full_output = "".join(output_lines)

        process.wait()

        if not print_output:
            full_output = process.stdout.read()

        if check and process.returncode != 0:
            raise subprocess.CalledProcessError(process.returncode, command, output=full_output)

        return full_output
    except FileNotFoundError:
        command_name = command[0] if isinstance(command, list) else command.split()[0]
        print(f"âŒ å‘½ä»¤æœªæ‰¾åˆ°: {command_name}. è¯·ç¡®ä¿å®ƒå·²å®‰è£…å¹¶åœ¨æ‚¨çš„ PATH ä¸­ã€‚")
        sys.exit(1)
    except subprocess.CalledProcessError as e:
        print(f"âŒ å‘½ä»¤æ‰§è¡Œå¤±è´¥ï¼Œè¿”å›ç : {e.returncode}")
        print(f"   å‘½ä»¤: {e.cmd}")
        print(f"   è¾“å‡º:\n{e.output}")
        raise


def get_commit_list(start_tag, end_tag, task_id, repo_path):
    """è·å–ä¸¤ä¸ª tag ä¹‹é—´çš„ commit SHA åˆ—è¡¨ï¼Œåœ¨æŒ‡å®šçš„ repo_path ä¸­æ“ä½œ"""
    tasks[task_id]['log'].append(f"\nâ„¹ï¸ å‡†å¤‡åœ¨éš”ç¦»ç¯å¢ƒ '{repo_path}' ä¸­åˆ‡æ¢åˆ°ä¸ tag '{end_tag}' ç›¸å…³çš„ release åˆ†æ”¯...")
    try:
        version_parts = end_tag.lstrip('v').split('.')
        branch_version = f"{version_parts[0]}.{version_parts[1]}"
        branch_name = f"release-{branch_version}"
        run_command(["git", "checkout", "-f", branch_name], work_dir=repo_path)
        tasks[task_id]['log'].append(f"âœ… æˆåŠŸåˆ‡æ¢åˆ°åˆ†æ”¯: {branch_name}")
    except IndexError:
        tasks[task_id]['log'].append(f"âš ï¸ è­¦å‘Š: æ— æ³•ä» tag '{end_tag}' æ¨æ–­å‡º release åˆ†æ”¯åã€‚")
    except subprocess.CalledProcessError:
        tasks[task_id]['log'].append(f"âš ï¸ è­¦å‘Š: åˆ‡æ¢åˆ°åˆ†æ”¯ '{branch_name}' å¤±è´¥ã€‚")
        return

    try:
        command = ["git", "rev-list", "--reverse", f"{start_tag}..{end_tag}"]
        output = run_command(command, repo_path)
        tasks[task_id]['log'].append(f"\nğŸ” è·å– {start_tag}..{end_tag} ä¹‹é—´çš„ commit åˆ—è¡¨...")
        commits = output.strip().split('\n')
        tasks[task_id]['log'].append(f"âœ… æ‰¾åˆ° {len(commits)} ä¸ª commitsã€‚")
        return [c for c in commits if c]
    except Exception as e:
        tasks[task_id]['log'].append(f"âŒ è·å– commits åˆ—è¡¨å¤±è´¥: {e}")
        return None

@retry(max_retries=3)
def compile_at_commit(commit_sha, task_id, version, repo_path):
    """åœ¨æŒ‡å®šçš„éš”ç¦» repo_path ä¸­ Checkout åˆ°æŒ‡å®š commit å¹¶è¿›è¡Œç¼–è¯‘"""
    tasks[task_id]['log'].append(f"\nğŸ”§ åœ¨ '{repo_path}' ä¸­åˆ‡æ¢åˆ° commit: {commit_sha[:8]} å¹¶å¼€å§‹ç¼–è¯‘...")
    try:
        if version == 'master' or version == 'nightly':
            go_version = DEFAULT_GO_VERSION
        else:
            version_key = ".".join(version.lstrip('v').split('.')[:2])
            go_version = TIDB_GO_VERSION_MAP.get(version_key, DEFAULT_GO_VERSION)

        run_command(["git", "checkout", "-f", commit_sha], work_dir=repo_path)
        tasks[task_id]['log'].append(f"âœ… Git checkout æˆåŠŸã€‚")

        tasks[task_id]['log'].append(f"âš™ï¸ æ­£åœ¨ä¸º TiDB ç‰ˆæœ¬ '{version}' è®¾ç½® Go ç‰ˆæœ¬ä¸º: {go_version} (ä¸´æ—¶)...")

        # éªŒè¯ Go ç‰ˆæœ¬æ˜¯å¦åˆ‡æ¢æˆåŠŸï¼ˆé€šè¿‡ run_command çš„ go_version å‚æ•°ï¼‰
        run_command(["go", "version"], work_dir=repo_path, print_output=True, go_version=go_version)

        # ç¼–è¯‘ TiDB serverï¼Œå¹¶ä¼ å…¥ go_version
        run_command(COMPILE_COMMAND.split(), work_dir=repo_path, print_output=True, go_version=go_version)

        binary_full_path = os.path.join(repo_path, TIDB_BINARY_PATH)
        if not os.path.exists(binary_full_path):
            raise FileNotFoundError(f"ç¼–è¯‘äº§ç‰© {binary_full_path} æœªæ‰¾åˆ°ï¼")

        tasks[task_id]['log'].append(f"âœ… ç¼–è¯‘æˆåŠŸ: {binary_full_path}")
        return binary_full_path
    except (subprocess.CalledProcessError, FileNotFoundError) as e:
        tasks[task_id]['log'].append(f"âŒ åœ¨ commit {commit_sha[:8]} ç¼–è¯‘å¤±è´¥: {e}")
        return None
    except Exception as e:
        tasks[task_id]['log'].append(f"âŒ å‘ç”ŸæœªçŸ¥é”™è¯¯åœ¨ç¼–è¯‘æ—¶: {e}")
        return None


# --- è¾…åŠ©å‡½æ•° ---

def get_tidb_versions():
    """é€šè¿‡ tiup list tidb è·å–å¯ç”¨çš„ TiDB ç‰ˆæœ¬åˆ—è¡¨"""
    try:
        subprocess.run(["tiup", "update", "--self"], check=True, capture_output=True, text=True, timeout=120)
        result = subprocess.run(
            ["tiup", "list", "tidb"],
            check=True,
            capture_output=True,
            text=True,
            timeout=60
        )
        versions = []
        for line in result.stdout.splitlines():
            if line.strip().startswith('v') and 'Available versions' not in line and '---' not in line:
                version = line.split()[0]
                if all(c in 'v0123456789.' for c in version):
                    if len(version) <= 4:
                        continue
                    versions.append(version)
        versions.sort(key=Version, reverse=True)
        return versions
    except Exception as e:
        print(f"è·å– TiDB ç‰ˆæœ¬å¤±è´¥: {e}")
        return ["v8.1.0", "v8.0.0", "v7.5.1", "v7.1.3", "v6.5.9", "v6.1.7", "v5.4.3", "v4.0.16"]


def run_sql_on_tidb(sql, port):
    """åœ¨æŒ‡å®šçš„ TiDB å®ä¾‹ä¸Šæ‰§è¡Œ SQL"""
    result_str = ""
    try:
        conn = mysql.connector.connect(
            host='127.0.0.1',
            port=port,
            user='root',
            password='',
            database='test',
            autocommit=True,
            connection_timeout=20
        )
        cursor = conn.cursor()
        for stmt in sql.split(';'):
            if stmt.strip():
                cursor.execute(stmt)
                if cursor.with_rows:
                    rows = cursor.fetchall()
                    result_str += str(rows) + "\n"
        conn.commit()
        cursor.close()
        conn.close()
        return result_str, True
    except mysql.connector.Error as err:
        print(f"SQL æ‰§è¡Œå¤±è´¥: {err}")
        return str(err), False


def run_other_check(script_content, port, task_id):
    """æ‰§è¡Œå…¶ä»–æ£€æŸ¥è„šæœ¬"""
    tasks[task_id]['log'].append("--- å¼€å§‹å…¶ä»–æ£€æŸ¥ ---")
    log_dir_query = "show config where type='tidb' and name='log.file.filename';"
    try:
        result, success = run_sql_on_tidb(log_dir_query, port)
        if not success or not result:
            msg = "è·å– TiDB æ—¥å¿—ç›®å½•å¤±è´¥ã€‚"
            tasks[task_id]['log'].append(f"âŒ {msg}")
            return "Failure", msg
        data_list = ast.literal_eval(result)
        log_file_path = data_list[0][3]
        base_dir = os.path.dirname(os.path.dirname(log_file_path))
        tasks[task_id]['log'].append(f"âœ… æˆåŠŸè·å–åˆ°tidbæ—¥å¿—ç›®å½•: {log_file_path}")
        tasks[task_id]['log'].append(f"âœ… è„šæœ¬å°†ä¼šåœ¨æ­¤åŸºç¡€ç›®å½•æ‰§è¡Œ: {base_dir}")
    except Exception as e:
        msg = f"è§£æ TiDB æ—¥å¿—ç›®å½•æ—¶å‡ºé”™: {e}"
        tasks[task_id]['log'].append(f"âŒ {msg}")
        return "Failure", msg

    script_path = os.path.join(base_dir, f"check_script_{task_id[:8]}.sh")
    try:
        with open(script_path, 'w') as f:
            f.write("#!/bin/bash\n")
            f.write(script_content)
        st = os.stat(script_path)
        os.chmod(script_path, st.st_mode | stat.S_IEXEC)
        tasks[task_id]['log'].append(f"âœ… æ£€æŸ¥è„šæœ¬å·²ä¿å­˜åˆ°: {script_path}")
        tasks[task_id]['log'].append(f"ğŸš€ æ‰§è¡Œæ£€æŸ¥è„šæœ¬...")
        process = subprocess.run(
            ['/bin/bash', script_path], capture_output=True, text=True, timeout=120, cwd=base_dir
        )
        script_output = process.stdout.strip() + "\n" + process.stderr.strip()
        tasks[task_id]['log'].append(f"è„šæœ¬è¾“å‡º:\n{script_output}")
        if process.returncode == 0:
            tasks[task_id]['log'].append("âœ… å…¶ä»–æ£€æŸ¥é€šè¿‡ (è„šæœ¬è¿”å›å€¼ä¸º 0)ã€‚")
            return "Success", script_output
        else:
            tasks[task_id]['log'].append(f"âŒ å…¶ä»–æ£€æŸ¥å¤±è´¥ (è„šæœ¬è¿”å›å€¼ä¸º {process.returncode})ã€‚")
            return "Failure", script_output
    except Exception as e:
        msg = f"æ‰§è¡Œæ£€æŸ¥è„šæœ¬æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}"
        tasks[task_id]['log'].append(f"âŒ {msg}")
        return "Failure", msg
    finally:
        if os.path.exists(script_path):
            os.remove(script_path)

def test_single_version(version, sql, expected_sql_result, other_check_script, task_id, index, cleanup_after=False,
                        commit='', binary_path=None):
    port_offset = random.randint(10000, 30000)
    sql_port = 4000 + port_offset
    dashboard_port = 2379 + port_offset
    log_dir = "logs"
    os.makedirs(log_dir, exist_ok=True)
    log_filename = f"{log_dir}/task_{task_id[:8]}_{version}_{commit[:7] if commit else ''}.log"

    log_message = f"ç‰ˆæœ¬ {version}" + (f" (commit {commit[:7]})" if commit else "")
    tasks[task_id]['log'].append(f"{log_message}: å‡†å¤‡å¯åŠ¨é›†ç¾¤ (SQL Port: {sql_port})...")
    result_data = {'version': f"{version}-{commit}" if commit else version}
    process = None
    log_file = None
    startup_success = False
    MAX_STARTUP_RETRIES = 3

    for attempt in range(1, MAX_STARTUP_RETRIES + 1):
        log_file = None
        try:
            # æ¸…ç†ä¸Šä¸€æ¬¡å¤±è´¥çš„è¿›ç¨‹
            if process and process.poll() is None:
                process.terminate()
                process.wait(timeout=10)

            log_file = open(log_filename, 'w', encoding='utf-8')
            # å¦‚æœæä¾›äº† binary_path (æ¥è‡ªç¼–è¯‘)ï¼Œåˆ™ä½¿ç”¨ --db.binpath å¯åŠ¨
            if commit and binary_path:
                cmd = ['tiup', 'playground', f'--db.binpath={binary_path}', version, f'--port-offset={port_offset}',
                   '--without-monitor', '--kv', str(COMPONENT_COUNTS['tikv']), '--tiflash',
                   str(COMPONENT_COUNTS['tiflash']),
                   '--pd', str(COMPONENT_COUNTS['pd']), '--db', str(COMPONENT_COUNTS['tidb'])]
            else:
                cmd = ['tiup', 'playground', version, f'--port-offset={port_offset}', '--without-monitor',
                   '--kv', str(COMPONENT_COUNTS['tikv']), '--tiflash', str(COMPONENT_COUNTS['tiflash']),
                   '--pd', str(COMPONENT_COUNTS['pd']), '--db', str(COMPONENT_COUNTS['tidb'])]

            process = subprocess.Popen(cmd, stdout=log_file, stderr=log_file, text=True, encoding='utf-8')
            if attempt == 1:
                tasks[task_id]['processes'].append(
                    {'version': version, 'process': process, 'offset': port_offset, 'log_file': log_filename})

            tasks[task_id]['log'].append(
            f"{log_message}: é›†ç¾¤å¯åŠ¨å°è¯• {attempt}/{MAX_STARTUP_RETRIES} (PID: {process.pid}, SQL Port: {sql_port})...")

            ready = False
            for _ in range(36):  # Wait up to 180 seconds
                time.sleep(5)
                try:
                    conn = mysql.connector.connect(host='127.0.0.1', port=sql_port, user='root', password='',
                                               connection_timeout=5)
                    conn.close()
                    ready = True
                    tasks[task_id]['log'].append(f"âœ… {log_message}: TiDB æœåŠ¡åœ¨ç«¯å£ {sql_port} ä¸Šå·²å°±ç»ªã€‚")
                    break
                except mysql.connector.Error:
                    if process.poll() is not None:
                        raise Exception(f"TiUP è¿›ç¨‹æ„å¤–é€€å‡ºã€‚è¯·æ£€æŸ¥æ—¥å¿—: {log_filename}")
            if not ready:
                raise Exception("TiDB æœåŠ¡å¯åŠ¨è¶…æ—¶")
            startup_success = True
            break  # æˆåŠŸï¼Œè·³å‡ºé‡è¯•å¾ªç¯
        except Exception as e:
            error_msg = f"âŒ é›†ç¾¤å¯åŠ¨å°è¯• {attempt}/{MAX_STARTUP_RETRIES} å¤±è´¥: {e}"
            tasks[task_id]['log'].append(error_msg)
            if log_file: log_file.close()
            if attempt < MAX_STARTUP_RETRIES:
                time.sleep(5)
            else:  # æ‰€æœ‰é‡è¯•å¤±è´¥
                result_data = {'version': version, 'status': 'Failure',
                               'error': f"é›†ç¾¤å¯åŠ¨åœ¨ {MAX_STARTUP_RETRIES} æ¬¡å°è¯•åå¤±è´¥: {e}"}
                tasks[task_id]['results'][index] = result_data
                if process: process.terminate()
                return  # é€€å‡ºå‡½æ•°
        finally:
            if log_file: log_file.close()

        tasks[task_id]['processes'].append(
            {'version': version, 'process': process, 'offset': port_offset, 'log_file': log_filename})
        tasks[task_id]['log'].append(f"{log_message}: é›†ç¾¤è¿›ç¨‹å·²å¯åŠ¨ (PID: {process.pid})ï¼Œç­‰å¾…æœåŠ¡å°±ç»ª...")

    try:
        if commit:
            v_result, success = run_sql_on_tidb('select tidb_version();', sql_port)
            if not success or commit not in ''.join(v_result.split()):
                raise Exception(f"TiDB binary ç‰ˆæœ¬ä¸æ­£ç¡®! æœŸæœ›åŒ…å« {commit[:10]}, å®é™…ä¸º {v_result}")
            tasks[task_id]['log'].append("âœ… TiDB binary ç‰ˆæœ¬æ£€æŸ¥é€šè¿‡ã€‚")

        # --- æ‰§è¡Œæ£€æŸ¥ ---
        sql_check_passed, other_check_passed = None, None
        final_status = "Success"

        if expected_sql_result is not None:
            actual_sql_result, success = run_sql_on_tidb(sql, sql_port)
            result_data.update({'expected_sql': expected_sql_result, 'actual_sql': actual_sql_result})
            if expected_sql_result.strip():
                if ''.join(expected_sql_result.split()) in ''.join(actual_sql_result.split()):
                    sql_check_passed = True
                else:
                    sql_check_passed = False
            else:
                # if expected is emptyï¼Œthen sql executed success means check pass.
                if success:
                    print("expected sql is empty, and sql executed success")
                    sql_check_passed = True
                else:
                    sql_check_passed = False

        if other_check_script.strip():
            other_status, other_output = run_other_check(other_check_script, sql_port, task_id)
            result_data.update({'other_check_status': other_status, 'other_check_output': other_output})
            other_check_passed = (other_status == "Success")

        if sql_check_passed is False or other_check_passed is False:
            final_status = "Failure"

        result_data.update({'status': final_status, 'sql_port': sql_port})
    except Exception as e:
        error_msg = f"æµ‹è¯• {log_message} æ—¶å‘ç”Ÿé”™è¯¯: {e}"
        tasks[task_id]['log'].append(f"âŒ {error_msg}")
        result_data = {'version': version, 'status': 'Failure', 'error': str(e)}
    finally:
        if cleanup_after and process:
            tasks[task_id]['log'].append(f"{log_message}: æµ‹è¯•å®Œæˆï¼Œæ¸…ç†é›†ç¾¤ (PID: {process.pid})...")
            process.terminate()
            process.wait()

    tasks[task_id]['results'][index] = result_data


# --- è·¯ç”± ---
@app.route('/locales/<path:filename>')
def serve_locales(filename):
    return send_from_directory(os.path.join(app.root_path, 'locales'), filename)


@app.route('/')
def index():
    versions = get_tidb_versions()
    return render_template('index.html', versions=versions)


@app.route('/locate')
def locate_page():
    return render_template('locate.html')


@app.route('/start_test', methods=['POST'])
def start_test():
    global COMPONENT_COUNTS
    data = request.json
    selected_versions = data.get('versions', [])
    sql = data.get('sql')
    expected_sql = data.get('expected_sql_result', '').strip()
    other_script = data.get('other_check_script', '').strip()

    COMPONENT_COUNTS = {
        'tidb': int(data.get('tidb') or COMPONENT_COUNTS['tidb']),
        'tikv': int(data.get('tikv') or COMPONENT_COUNTS['tikv']),
        'pd': int(data.get('pd') or COMPONENT_COUNTS['pd']),
        'tiflash': int(data.get('tiflash') or COMPONENT_COUNTS['tiflash'])
    }

    task_id = str(uuid4())
    tasks[task_id] = {'status': 'running', 'log': [], 'results': [{} for _ in selected_versions], 'processes': [],
                      'type': 'test'}
    session.setdefault('task_ids', []).append(task_id)
    session.modified = True

    threads = []
    for i, version in enumerate(selected_versions):
        thread = threading.Thread(target=test_single_version,
                                  args=(version, sql, expected_sql, other_script, task_id, i, False, ''))
        threads.append(thread)
        thread.start()

    def wait_for_completion():
        for t in threads:
            t.join()
        tasks[task_id]['status'] = 'complete'

    threading.Thread(target=wait_for_completion).start()

    return jsonify({'task_id': task_id})


def run_binary_search_with_version(start_v_str, end_v_str, sql, expected_sql, other_check, task_id):
    """äºŒåˆ†æŸ¥æ‰¾é€»è¾‘ï¼Œç°åœ¨åŒ…å«éš”ç¦»ç¯å¢ƒçš„åˆ›å»ºå’Œæ¸…ç†"""
    task_repo_path = os.path.join(TIDB_WORKTREE_BASE, task_id)

    try:
        # --- åˆ›å»ºéš”ç¦»ç¯å¢ƒ ---
        tasks[task_id]['log'].append(f"ä¸ºä»»åŠ¡ {task_id} åˆ›å»ºéš”ç¦»çš„å·¥ä½œç›®å½•: {task_repo_path}")
        os.makedirs(TIDB_WORKTREE_BASE, exist_ok=True)
        # ä» end_v_str æ¨æ–­åˆ†æ”¯
        version_parts = end_v_str.lstrip('v').split('.')
        branch_version = f"{version_parts[0]}.{version_parts[1]}"
        branch_name = f"release-{branch_version}"
        run_command(["git", "worktree", "add", "-f", task_repo_path, branch_name], work_dir=TIDB_REPO_PATH)
        tasks[task_id]['log'].append(f"âœ… Git worktree åˆ›å»ºæˆåŠŸï¼ŒåŸºäºåˆ†æ”¯ {branch_name}ã€‚")

        # --- å†…éƒ¨å‡½æ•°ç°åœ¨ä½¿ç”¨ repo_path ---
        def commit_binary_search_logic(start_version, end_version, repo_path):
            commits = get_commit_list(start_version, end_version, task_id, repo_path)
            if not commits: return None
            low, high, first_bad_commit = 0, len(commits) - 1, None
            while low <= high:
                mid = (low + high) // 2
                commit_sha = commits[mid]
                tasks[task_id]['log'].append(
                    f"\n--- æ­£åœ¨æµ‹è¯•ç¬¬ {mid + 1}/{len(commits)} ä¸ª commit: {commit_sha[:12]} ---")

                binary_path = compile_at_commit(commit_sha, task_id, end_version, repo_path)
                if binary_path is None:
                    high = mid - 1
                    continue

                result_index = len(tasks[task_id]['results'])
                tasks[task_id]['results'].append({})
                test_single_version(end_version, sql, expected_sql, other_check, task_id, result_index,
                                    cleanup_after=True, commit=commit_sha, binary_path=binary_path)

                result_data = tasks[task_id]['results'][result_index]
                if result_data.get('status') == 'Failure':
                    first_bad_commit = commit_sha
                    high = mid - 1
                elif result_data.get('status') == 'Success':
                    low = mid + 1
                else:
                    tasks[task_id]['log'].append(f"commit {commit_sha[:7]} æµ‹è¯•æ—¶å‘ç”Ÿç¯å¢ƒé”™è¯¯ï¼Œä¸­æ­¢ã€‚")
                    tasks[task_id]['status'] = 'error'
                    return None
            return first_bad_commit

        # ... (binary_search_logic and baseline checks remain the same, they call test_single_version which doesn't need repo_path)
        all_versions = get_tidb_versions()

        def binary_search_logic(start_version, end_version):
            # This logic doesn't directly interact with git repo, so no repo_path is needed
            search_space = [v for v in all_versions if
                            Version(v) >= Version(start_version) and Version(v) <= Version(end_version)]
            search_space.sort(key=Version)
            low, high, first_bad_version = 0, len(search_space) - 1, None
            while low <= high:
                mid_idx = (low + high) // 2
                version_to_test = search_space[mid_idx]
                result_index = len(tasks[task_id]['results'])
                tasks[task_id]['results'].append({})
                test_single_version(version_to_test, sql, expected_sql, other_check, task_id, result_index,
                                    cleanup_after=True)
                result_data = tasks[task_id]['results'][result_index]
                if result_data.get('status') == 'Failure':
                    first_bad_version = version_to_test
                    high = mid_idx - 1
                elif result_data.get('status') == 'Success':
                    low = mid_idx + 1
                else:
                    tasks[task_id]['log'].append(f"ç‰ˆæœ¬ {version_to_test} æµ‹è¯•æ—¶å‘ç”Ÿç¯å¢ƒé”™è¯¯ï¼Œä¸­æ­¢ã€‚")
                    tasks[task_id]['status'] = 'error'
                    return None
            return first_bad_version

        # --- æ‰§è¡Œæµç¨‹ ---
        # # 1. åŸºçº¿æ£€æŸ¥
        # tasks[task_id]['log'].append(f"\n--- æ­£åœ¨æ‰§è¡ŒåŸºçº¿æ£€æŸ¥: {start_v_str} ---")
        # start_index = len(tasks[task_id]['results'])
        # tasks[task_id]['results'].append({})
        # test_single_version(start_v_str, sql, expected_sql, other_check, task_id, start_index, cleanup_after=True)
        # start_result = tasks[task_id]['results'][start_index]
        # if start_result.get('status') == 'Failure':
        #     tasks[task_id]['log'].append(f"\nâŒ åŸºçº¿æ£€æŸ¥å¤±è´¥: èµ·å§‹ç‰ˆæœ¬ {start_v_str} å·²ä¸ç¬¦åˆé¢„æœŸã€‚")
        #     tasks[task_id]['final_result'] = "æœ¬èŒƒå›´å†…æ— æ³•æ‰¾åˆ°å¼•å…¥é—®é¢˜çš„pr,è¯·åœ¨æ›´æ—©çš„ç‰ˆæœ¬æˆ–è€… commit èŒƒå›´å†…æŸ¥æ‰¾"
        #     return
        #
        # # 2. å¥å…¨æ€§æ£€æŸ¥
        # tasks[task_id]['log'].append(f"\n--- æ­£åœ¨æ‰§è¡Œå¥å…¨æ€§æ£€æŸ¥: {end_v_str} ---")
        # end_index = len(tasks[task_id]['results'])
        # tasks[task_id]['results'].append({})
        # test_single_version(end_v_str, sql, expected_sql, other_check, task_id, end_index, cleanup_after=True)
        # end_result = tasks[task_id]['results'][end_index]
        # if end_result.get('status') == 'Success':
        #     error_msg = f"å¥å…¨æ€§æ£€æŸ¥å¤±è´¥: 'Bug ä¸ŠæŠ¥ç‰ˆæœ¬' ({end_v_str}) çš„æµ‹è¯•ç»“æœä¸ºæˆåŠŸï¼Œæ— æ³•è¿›è¡ŒäºŒåˆ†æŸ¥æ‰¾ã€‚"
        #     tasks[task_id]['log'].append(f"\nâŒ {error_msg}")
        #     tasks[task_id]['final_result'] = error_msg
        #     return

        # 3. å¼€å§‹ç‰ˆæœ¬äºŒåˆ†æŸ¥æ‰¾
        found_version = binary_search_logic(start_v_str, end_v_str)
        if not found_version:
            tasks[task_id]['final_result'] = f"åœ¨ {start_v_str}-{end_v_str} èŒƒå›´å†…æœªæ‰¾åˆ°ä¸ç¬¦åˆé¢„æœŸçš„ç‰ˆæœ¬ã€‚"
            return

        tasks[task_id]['log'].append(f"\n---- å®šä½åˆ°ç¬¬ä¸€ä¸ªå‡ºé”™çš„ç‰ˆæœ¬æ˜¯: {found_version} ----")
        tasks[task_id]['final_result'] = f"å®šä½åˆ°ç¬¬ä¸€ä¸ªå‡ºé”™çš„ç‰ˆæœ¬æ˜¯: {found_version}"

        # 4. å¼€å§‹ Commit äºŒåˆ†æŸ¥æ‰¾
        tidb_versions = get_tidb_versions()
        good_version_index = tidb_versions.index(found_version) + 1
        good_version = tidb_versions[good_version_index]

        found_commit = commit_binary_search_logic(good_version, found_version, task_repo_path)
        if found_commit:
            output = run_command(["git", "show", found_commit, "--no-patch"], work_dir=task_repo_path)

            tasks[task_id][
                'final_result'] = f"å®šä½åˆ°ç¬¬ä¸€ä¸ªå‡ºé”™çš„commitæ˜¯: {found_version}-{found_commit}\n\nCommit Info:\n{output}"
        else:
            tasks[task_id]['final_result'] += f"\nä½†åœ¨ {good_version} å’Œ {found_version} ä¹‹é—´æœªå®šä½åˆ°å…·ä½“çš„ commitã€‚"

    except Exception as e:
        tasks[task_id]['log'].append(f"âŒ äºŒåˆ†æŸ¥æ‰¾è¿‡ç¨‹ä¸­å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
        tasks[task_id]['status'] = 'error'
    finally:
        # --- æ¸…ç†éš”ç¦»ç¯å¢ƒ ---
        if os.path.exists(task_repo_path):
            tasks[task_id]['log'].append(f"æ¸…ç†ä»»åŠ¡ {task_id} çš„å·¥ä½œç›®å½•: {task_repo_path}")
            try:
                # ä½¿ç”¨ git worktree remove æ›´å¹²å‡€
                run_command(["git", "worktree", "remove", "--force", task_repo_path], work_dir=TIDB_REPO_PATH)
            except Exception as e:
                tasks[task_id]['log'].append(f"âš ï¸ Git worktree remove å¤±è´¥: {e}. å°è¯•æ‰‹åŠ¨åˆ é™¤ç›®å½•...")
                shutil.rmtree(task_repo_path, ignore_errors=True)
        tasks[task_id]['status'] = 'complete'


def run_binary_search_with_commit(start_commit, end_commit, branch, sql, expected_sql, other_check, task_id):
    """äºŒåˆ†æŸ¥æ‰¾é€»è¾‘ï¼Œç°åœ¨åŒ…å«éš”ç¦»ç¯å¢ƒçš„åˆ›å»ºå’Œæ¸…ç†"""
    task_repo_path = os.path.join(TIDB_WORKTREE_BASE, task_id)

    try:
        # --- åˆ›å»ºéš”ç¦»ç¯å¢ƒ ---
        tasks[task_id]['log'].append(f"ä¸ºä»»åŠ¡ {task_id} åˆ›å»ºéš”ç¦»çš„å·¥ä½œç›®å½•: {task_repo_path}")
        os.makedirs(TIDB_WORKTREE_BASE, exist_ok=True)
        run_command(["git", "worktree", "add", "-f", task_repo_path, branch], work_dir=TIDB_REPO_PATH)
        tasks[task_id]['log'].append(f"âœ… Git worktree åˆ›å»ºæˆåŠŸï¼ŒåŸºäºåˆ†æ”¯ {branch}ã€‚")

        # --- å†…éƒ¨å‡½æ•° ---
        def commit_binary_search_logic(repo_path):
            command = ["git", "rev-list", "--reverse", f"{start_commit}..{end_commit}"]
            result = run_command(command, work_dir=repo_path)
            commits_after_start = [line for line in result.strip().split('\n') if line]
            commits = [start_commit] + commits_after_start

            low, high, first_bad_commit = 0, len(commits) - 1, None

            while low <= high:
                mid = (low + high) // 2
                commit_sha = commits[mid]
                tasks[task_id]['log'].append(
                    f"\n--- æ­£åœ¨æµ‹è¯•ç¬¬ {mid + 1}/{len(commits)} ä¸ª commit: {commit_sha[:12]} ---")

                install_version = 'nightly' if branch == 'master' else f'v{branch.replace("release-", "")}.0'
                binary_path = compile_at_commit(commit_sha, task_id, install_version, repo_path)
                if binary_path is None:
                    high = mid - 1
                    continue

                result_index = len(tasks[task_id]['results'])
                tasks[task_id]['results'].append({})
                test_single_version(install_version, sql, expected_sql, other_check, task_id, result_index,
                                    cleanup_after=True, commit=commit_sha, binary_path=binary_path)

                result_data = tasks[task_id]['results'][result_index]
                if result_data.get('status') == 'Failure':
                    first_bad_commit = commit_sha
                    high = mid - 1
                elif result_data.get('status') == 'Success':
                    low = mid + 1
                else:
                    tasks[task_id]['log'].append(f"commit {commit_sha[:7]} æµ‹è¯•æ—¶å‘ç”Ÿç¯å¢ƒé”™è¯¯ï¼Œä¸­æ­¢ã€‚")
                    tasks[task_id]['status'] = 'error'
                    return None
            return first_bad_commit

        # def test_a_commit(commit_sha, index, repo_path):
        #     install_version = 'nightly' if branch == 'master' else f'v{branch.replace("release-", "")}.0'
        #     binary_path = compile_at_commit(commit_sha, task_id, install_version, repo_path)
        #     if binary_path is None:
        #         tasks[task_id]['results'][index] = {'version': commit_sha, 'status': 'Failure', 'error': 'ç¼–è¯‘å¤±è´¥'}
        #         return
        #     test_single_version(install_version, sql, expected_sql, other_check, task_id, index, cleanup_after=True,
        #                         commit=commit_sha, binary_path=binary_path)

        # --- æ‰§è¡Œæµç¨‹ ---
        # 1. åŸºçº¿æ£€æŸ¥
        # tasks[task_id]['log'].append(f"\n--- æ­£åœ¨æ‰§è¡ŒåŸºçº¿æ£€æŸ¥ (èµ·å§‹ Commit): {start_commit[:7]} ---")
        # start_index = len(tasks[task_id]['results'])
        # tasks[task_id]['results'].append({})
        # test_a_commit(start_commit, start_index, task_repo_path)
        #
        # start_result = tasks[task_id]['results'][start_index]
        # if start_result.get('status') == 'Failure':
        #     tasks[task_id]['log'].append(f"\nâŒ åŸºçº¿æ£€æŸ¥å¤±è´¥: èµ·å§‹ Commit {start_commit[:7]} å·²ä¸ç¬¦åˆé¢„æœŸã€‚")
        #     tasks[task_id]['final_result'] = "æœ¬èŒƒå›´å†…æ— æ³•æ‰¾åˆ°å¼•å…¥é—®é¢˜çš„pr,è¯·åœ¨æ›´æ—©çš„ç‰ˆæœ¬æˆ–è€…commit èŒƒå›´å†…æŸ¥æ‰¾"
        #     return

        # 2. å¼€å§‹äºŒåˆ†æŸ¥æ‰¾
        found_commit = commit_binary_search_logic(task_repo_path)
        if found_commit:
            output = run_command(["git", "show", found_commit, "--no-patch"], work_dir=task_repo_path)
            tasks[task_id]['final_result'] = f"å®šä½åˆ°ç¬¬ä¸€ä¸ªå‡ºé”™çš„commitæ˜¯: {found_commit}\n\nCommit Info:\n{output}"
        else:
            tasks[task_id][
                'final_result'] = f"åœ¨ {branch} åˆ†æ”¯çš„ {start_commit[:7]}..{end_commit[:7]} èŒƒå›´å†…æœªæ‰¾åˆ°ä¸ç¬¦åˆé¢„æœŸçš„commitã€‚"

    except Exception as e:
        tasks[task_id]['log'].append(f"âŒ äºŒåˆ†æŸ¥æ‰¾è¿‡ç¨‹ä¸­å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
        tasks[task_id]['status'] = 'error'
    finally:
        # --- æ¸…ç†éš”ç¦»ç¯å¢ƒ ---
        if os.path.exists(task_repo_path):
            tasks[task_id]['log'].append(f"æ¸…ç†ä»»åŠ¡ {task_id} çš„å·¥ä½œç›®å½•: {task_repo_path}")
            try:
                run_command(["git", "worktree", "remove", "--force", task_repo_path], work_dir=TIDB_REPO_PATH)
            except Exception as e:
                tasks[task_id]['log'].append(f"âš ï¸ Git worktree remove å¤±è´¥: {e}. å°è¯•æ‰‹åŠ¨åˆ é™¤ç›®å½•...")
                shutil.rmtree(task_repo_path, ignore_errors=True)
        tasks[task_id]['status'] = 'complete'


@app.route('/start_locate', methods=['POST'])
def start_locate():
    global COMPONENT_COUNTS
    data = request.json
    locate_mode = data.get('locate_mode')
    sql = data.get('sql')
    expected_sql_result = data.get('expected_sql_result', '').strip()
    other_check_script = data.get('other_check_script', '').strip()

    COMPONENT_COUNTS = {
        'tidb': int(data.get('tidb') or COMPONENT_COUNTS['tidb']),
        'tikv': int(data.get('tikv') or COMPONENT_COUNTS['tikv']),
        'pd': int(data.get('pd') or COMPONENT_COUNTS['pd']),
        'tiflash': int(data.get('tiflash') or COMPONENT_COUNTS['tiflash'])
    }

    task_id = str(uuid4())
    tasks[task_id] = {'status': 'running', 'log': [], 'results': [], 'processes': [], 'type': 'locate'}
    session.setdefault('task_ids', []).append(task_id)
    session.modified = True

    if locate_mode == 'version':
        bug_version = data.get('bug_version')
        start_version_str = data.get('start_version') or "v5.4.0"
        if not bug_version or Version(start_version_str) >= Version(bug_version):
            return jsonify({'error': 'ç‰ˆæœ¬è®¾ç½®æ— æ•ˆï¼šâ€œèµ·å§‹ç‰ˆæœ¬â€å¿…é¡»æ—©äºâ€œBug ä¸ŠæŠ¥ç‰ˆæœ¬â€'}), 400
        thread = threading.Thread(target=run_binary_search_with_version,
                                  args=(start_version_str, bug_version, sql, expected_sql_result, other_check_script,
                                        task_id))
    elif locate_mode == 'commit':
        branch = data.get('branch')
        start_commit = data.get('start_commit')
        end_commit = data.get('end_commit')
        if not all([branch, start_commit, end_commit]):
            return jsonify({'error': 'åˆ†æ”¯ã€èµ·å§‹ Commit å’Œç»“æŸ Commit å‡ä¸ºå¿…å¡«é¡¹'}), 400
        thread = threading.Thread(target=run_binary_search_with_commit,
                                  args=(start_commit, end_commit, branch, sql, expected_sql_result, other_check_script,
                                        task_id))
    else:
        return jsonify({'error': f'æœªçŸ¥çš„å®šä½æ¨¡å¼: {locate_mode}'}), 400

    thread.start()
    return jsonify({'task_id': task_id})


@app.route('/status/<task_id>')
def task_status(task_id):
    task = tasks.get(task_id)
    if not task:
        return jsonify({'status': 'not_found'}), 404

    serializable_task = {
        'status': task.get('status'),
        'log': task.get('log', []),
        'results': task.get('results', []),
        'type': task.get('type'),
        'final_result': task.get('final_result'),
    }
    return jsonify(serializable_task)


@app.route('/clean', methods=['POST'])
def clean_env():
    """æ¸…ç†å½“å‰ session åˆ›å»ºçš„æ‰€æœ‰ tiup playground è¿›ç¨‹å’Œæ—¥å¿—æ–‡ä»¶"""
    task_ids_to_clean = session.get('task_ids', [])
    cleaned_pids, deleted_logs, errors = [], [], []

    for task_id in task_ids_to_clean:
        task = tasks.get(task_id)
        if not task or not task.get('processes'):
            continue

        for proc_info in task['processes']:
            process = proc_info.get('process')
            if process and process.poll() is None:
                try:
                    pid = process.pid
                    process.terminate()
                    process.wait(timeout=30)
                    cleaned_pids.append(pid)
                except Exception as e:
                    errors.append(f"æ¸…ç†è¿›ç¨‹ PID {pid} å¤±è´¥: {e}")

            log_file = proc_info.get('log_file')
            if log_file and os.path.exists(log_file):
                try:
                    os.remove(log_file)
                    deleted_logs.append(log_file)
                except OSError as e:
                    errors.append(f"åˆ é™¤æ—¥å¿—æ–‡ä»¶ {log_file} å¤±è´¥: {e}")

    session['task_ids'] = []
    session.modified = True

    return jsonify({
        'message': 'æ¸…ç†å®Œæˆã€‚æ³¨æ„: æ‰‹åŠ¨åˆ›å»ºçš„ç¼–è¯‘ç›®å½• (å¦‚ /tmp/tidb_worktrees) åœ¨å¼‚å¸¸é€€å‡ºæ—¶å¯èƒ½éœ€è¦æ‰‹åŠ¨æ¸…ç†ã€‚',
        'cleaned_pids': cleaned_pids,
        'deleted_logs': deleted_logs,
        'errors': errors
    })


if __name__ == '__main__':
    # ç¡®ä¿ worktree åŸºå‡†ç›®å½•å­˜åœ¨
    os.makedirs(TIDB_WORKTREE_BASE, exist_ok=True)
    app.run(debug=True, host='0.0.0.0', port=5001)

